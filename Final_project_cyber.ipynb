{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_project_cyber.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsfgATLQKIi0"
      },
      "source": [
        "# Load Image\n",
        "import numpy as np, os \n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjjO6VGZIpMY"
      },
      "source": [
        "model = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
        "def get_bbox(img_arr):\n",
        "    detector_output = model(img_arr)\n",
        "    class_prob,class_id, class_boxes = detector_output[\"detection_scores\"], detector_output[\"detection_classes\"], detector_output[\"detection_boxes\"]\n",
        "\n",
        "    prob_max=tf.argmax(class_prob, axis=-1).numpy()[0]\n",
        "    class_label=class_id.numpy()[0][prob_max]\n",
        "    class_box=class_boxes.numpy()[0][prob_max]\n",
        "    return prob_max, class_box"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzOJKTL_lsrO"
      },
      "source": [
        "# Load images and apply patch\n",
        "img_path='/content/images/'\n",
        "patch_path = '/content/patch.jpg'\n",
        "\n",
        "for path in os.listdir(img_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path+path, grayscale=False, target_size=(512,512))\n",
        "    img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_arr = np.array([img_arr]) \n",
        "\n",
        "    prob_max, class_box=get_bbox(img_arr)\n",
        "\n",
        "    p_size=int((class_box[3]-class_box[1])*512//2.5)\n",
        "    patch = tf.keras.preprocessing.image.load_img(patch_path, grayscale=False, target_size=(p_size,p_size))\n",
        "    patch_arr = tf.keras.preprocessing.image.img_to_array(patch)\n",
        "    patch_arr = np.array([patch_arr]) \n",
        "\n",
        "    p_y=int((class_box[2]-class_box[0])*512//2)\n",
        "    p_x=int((class_box[3]-class_box[1])*512//2)\n",
        "    img_arr[0][p_y:p_y+p_size,p_x:p_x+p_size]=patch_arr\n",
        "\n",
        "    from keras.preprocessing.image import save_img\n",
        "    save_img(patched_img_path+path, img_arr[0])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-P62tedvV3I"
      },
      "source": [
        "  # Calculate gradient\n",
        "  loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "  original_label=tf.constant([0.85,0.40]) # We will train till People score is 0.40\n",
        "\n",
        "def calc_gradient(img):\n",
        "    with tf.GradientTape() as gt:\n",
        "        # Define the calculation that needs to be derived\n",
        "        gt.watch(img_tf)\n",
        "        img_tf=tf.cast(img_tf, tf.uint8)\n",
        "        detector_output = model(img_tf)\n",
        "        cls_outputs = detector_output[\"detection_scores\"]\n",
        "        prediction=cls_outputs[0][0:2]\n",
        "        loss = loss_object(original_label, prediction)\n",
        "    \n",
        "    # Get the gradients for the loss w.r.t image\n",
        "    grads = gt.gradient(loss, img_tf) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EMpdxsRwVjI"
      },
      "source": [
        "# train to update patch\n",
        "patched_img_path='/content/patched_images/'\n",
        "!mkdir {patched_img_path}\n",
        "\n",
        "for path in os.listdir(patched_img_path):\n",
        "\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path+path, grayscale=False, target_size=(512,512))\n",
        "    img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_arr = np.array([img_arr]) \n",
        "    grad=calc_gradient(img)\n",
        "\n",
        "    #Get class and BBox\n",
        "    prob_max, class_box=get_bbox(img_arr)\n",
        "\n",
        "    p_size=int((class_box[3]-class_box[1])*512//2.5)\n",
        "    p_y=int((class_box[2]-class_box[0])*512//2)\n",
        "    p_x=int((class_box[3]-class_box[1])*512//2)\n",
        "\n",
        "    img_arr[0][p_y:p_y+p_size,p_x:p_x+p_size]=patch_arr\n",
        "    patch=img_arr[0][p_y:p_y+p_size,p_x:p_x+p_size]\n",
        "    \n",
        "    patch=patch - eps*grad\n",
        "    img_arr[0][p_y:p_y+p_size,p_x:p_x+p_size]=patch\n",
        "\n",
        "    from keras.preprocessing.image import save_img\n",
        "    save_img(patched_img_path+path, img_arr[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoBuRfdqwVZN",
        "outputId": "1e8e213d-fef3-4a98-b725-199c3abc8189"
      },
      "source": [
        "# Calculate accuracy\n",
        "\n",
        "img_class=[]\n",
        "for path in os.listdir(img_path):\n",
        "\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path+path, grayscale=False, target_size=(512,512))\n",
        "    img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_arr = np.array([img_arr]) \n",
        "    prob_max, class_box=get_bbox(img_arr)\n",
        "    img_class.append(np.argmax(prob_max))\n",
        "\n",
        "acc=sum(img_class!=0)/len(img_class)\n",
        "\n",
        "print(f'accuracy - {acc}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy - 0.957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EwyZnsA9R2p",
        "outputId": "361c16e0-5026-49ed-a7a3-2d91213d64f4"
      },
      "source": [
        "# Test accuracy\n",
        "test_img_path='/content/val_images/'\n",
        "test_img_class=[]\n",
        "for path in os.listdir(test_img_path):\n",
        "\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path+path, grayscale=False, target_size=(512,512))\n",
        "    img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_arr = np.array([img_arr]) \n",
        "\n",
        "    prob_max, class_box=get_bbox(img_arr)\n",
        "\n",
        "    p_size=int((class_box[3]-class_box[1])*512//2.5)\n",
        "    p_y=int((class_box[2]-class_box[0])*512//2)\n",
        "    p_x=int((class_box[3]-class_box[1])*512//2)\n",
        "\n",
        "    img_arr[0][p_y:p_y+p_size,p_x:p_x+p_size]=patch # apply trained patch\n",
        "    # Check class again\n",
        "    prob_max, class_box=get_bbox(img_arr)\n",
        "    test_img_class.append(np.argmax(prob_max))\n",
        "\n",
        "acc=sum(test_img_class!=0)/len(test_img_class)\n",
        "\n",
        "print(f'accuracy - {acc}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy - 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFZpqDtem4t6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKM0oig6m4cH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}